{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RRYSu48huSUW",
        "outputId": "64e4984b-4b62-4709-847a-a021d4730a8f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.3.2 -> 24.0\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip -q install langchain openai tiktoken chromadb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-KFB7J_u_3L",
        "outputId": "a29ed872-d0bc-41ef-bb72-b6a0fe426a08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name: langchain\n",
            "Version: 0.1.0\n",
            "Summary: Building applications with LLMs through composability\n",
            "Home-page: https://github.com/langchain-ai/langchain\n",
            "Author: \n",
            "Author-email: \n",
            "License: MIT\n",
            "Location: c:\\python\\lib\\site-packages\n",
            "Requires: aiohttp, async-timeout, dataclasses-json, jsonpatch, langchain-community, langchain-core, langsmith, numpy, pydantic, PyYAML, requests, SQLAlchemy, tenacity\n",
            "Required-by: langchain-experimental, langserve, trulens-eval\n"
          ]
        }
      ],
      "source": [
        "!pip show langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "l6XPLPVrqEaV"
      },
      "outputs": [],
      "source": [
        "# !wget -q https://www.dropbox.com/s/vs6ocyvpzzncvwh/new_articles.zip\n",
        "# !unzip -q new_articles.zip -d new_articles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "from unstructured.partition.html import partition_html\n",
        "from langchain.vectorstores.chroma import Chroma\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import os\n",
        "import openai\n",
        "\n",
        "tfgm = \"https://tfgm.com/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def scrape_links(url):\n",
        "    try:\n",
        "        # Make a GET request to the URL\n",
        "        response = requests.get(url)\n",
        "        \n",
        "        # Check if the request was successful (status code 200)\n",
        "        if response.status_code == 200:\n",
        "            # Parse the HTML content using BeautifulSoup\n",
        "            soup = BeautifulSoup(response.content, 'html.parser')\n",
        "            \n",
        "            # Find all anchor tags (links) in the HTML\n",
        "            all_links = soup.find_all('a')\n",
        "            \n",
        "            # Extract the href attribute from each link\n",
        "            links = [link.get('href') for link in all_links]\n",
        "            \n",
        "            # Filter out None values and empty strings\n",
        "            links = [link for link in links if link is not None and link.strip()]\n",
        "            \n",
        "            return links\n",
        "        else:\n",
        "            print(f\"Failed to retrieve content. Status code: {response.status_code}\")\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['https://tfgm.com/', 'https://tfgm.com/travel-updates', 'https://tfgm.com/plan-a-journey', 'https://tfgm.com/tickets-and-passes', 'https://tfgm.com/the-bee-network', 'https://tfgm.comhttps://takechargetoday.co.uk/', 'https://tfgm.comhttps://www.visitsealife.com/manchester/tickets-prices/?utm_source=tfgm&utm_medium=partnership&utm_campaign=december2023', 'https://tfgm.com/travel-updates']\n"
          ]
        }
      ],
      "source": [
        "tfgm = \"https://tfgm.com\"\n",
        "all_links = scrape_links(tfgm)\n",
        "links = []\n",
        "if all_links:\n",
        "    for link in all_links:\n",
        "        links.append(f\"{tfgm}{link}\")\n",
        "mylinks = links[2:10]\n",
        "print(mylinks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "mylinks.append('https://tfgm.com/tickets-and-passes/discounted-and-free-travel/disabled-people/travel-pass-for-disabled-people')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "mylinks.append('https://tfgm.com/ways-to-pay/contactless-on-tram')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 50%|█████     | 5/10 [00:12<00:11,  2.30s/it]Error fetching or processing https://tfgm.comhttps://takechargetoday.co.uk/, exception: HTTPSConnectionPool(host='tfgm.comhttps', port=443): Max retries exceeded with url: //takechargetoday.co.uk/ (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000002721C5AE8F0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
            "Error fetching or processing https://tfgm.comhttps://www.visitsealife.com/manchester/tickets-prices/?utm_source=tfgm&utm_medium=partnership&utm_campaign=december2023, exception: HTTPSConnectionPool(host='tfgm.comhttps', port=443): Max retries exceeded with url: //www.visitsealife.com/manchester/tickets-prices/?utm_source=tfgm&utm_medium=partnership&utm_campaign=december2023 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000002721C5AEBC0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
            "100%|██████████| 10/10 [00:16<00:00,  1.67s/it]\n"
          ]
        }
      ],
      "source": [
        "from langchain.document_loaders import UnstructuredURLLoader\n",
        "loaders = UnstructuredURLLoader(urls= mylinks, show_progress_bar = True)\n",
        "docs=loaders.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Source: https://tfgm.com/\n",
            "Source: https://tfgm.com/travel-updates\n",
            "Source: https://tfgm.com/plan-a-journey\n",
            "Source: https://tfgm.com/tickets-and-passes\n",
            "Source: https://tfgm.com/the-bee-network\n",
            "Source: https://tfgm.com/travel-updates\n",
            "Source: https://tfgm.com/tickets-and-passes/discounted-and-free-travel/disabled-people/travel-pass-for-disabled-people\n",
            "Source: https://tfgm.com/ways-to-pay/contactless-on-tram\n"
          ]
        }
      ],
      "source": [
        "for doc in docs:\n",
        "    print(f\"Source: {doc.metadata['source']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7AnZQpL_IZZZ"
      },
      "source": [
        "# LangChain multi-doc retriever with ChromaDB\n",
        "\n",
        "***New Points***\n",
        "- Multiple Files\n",
        "- ChromaDB\n",
        "- Source info\n",
        "- gpt-3.5-turbo API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqwsGJDhvAQ5"
      },
      "source": [
        "## Setting up LangChain\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "API Key: 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\n"
          ]
        }
      ],
      "source": [
        "# Load environment variables from the .env file\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "# Access the API key using the environment variable name\n",
        "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "# Check if the API key is available\n",
        "if openai_api_key is not None:\n",
        "    # Use the API key in your code\n",
        "    print(f\"API Key: {openai_api_key}\")\n",
        "else:\n",
        "    print(\"API Key not found. Check your .env file.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dNA4TsHpu6OM"
      },
      "outputs": [],
      "source": [
        "documents = docs\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load environment variables from the .env file\n",
        "load_dotenv()\n",
        "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "print(openai_api_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "openai_api_key\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "XHVE9uFb3Ajj"
      },
      "outputs": [],
      "source": [
        "from langchain.vectorstores import Chroma\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.document_loaders import DirectoryLoader\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UcQKUId3X2M"
      },
      "source": [
        "## Load multiple and process documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PRSeXXc_3Ypj"
      },
      "outputs": [],
      "source": [
        "# Load and process the text files\n",
        "# loader = TextLoader('single_text_file.txt')\n",
        "# loader = DirectoryLoader('./new_articles/', glob=\"./*.txt\", loader_cls=TextLoader)\n",
        "\n",
        "# documents = loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "3__nT0D4Fkmg"
      },
      "outputs": [],
      "source": [
        "#splitting the text into\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "texts = text_splitter.split_documents(docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TlU5AlqY4gwj",
        "outputId": "d78fb098-3161-42cd-8ce9-5f98f4ef91d2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "95"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bg6-9jwU4ja_",
        "outputId": "02f45055-0e09-42ba-9ff3-0e7850f06cae"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Document(page_content='Say yellow to the Bee Network\\n        The first Bee Network buses are now running in parts of Greater Manchester.\\n                    \\n                        Find out what the Bee Network means for you\\n\\nRate your journey\\n        We want to hear your views to help us deliver a better Bee Network for Greater Manchester.\\n                    \\n                        Rate your journey\\n\\nPlanned engineering works on Metrolink\\n        Visit our dedicated webpage to find out how the works could affect your journeys.\\n                    \\n                        Find out about planned works on the tram\\n\\nNew sponsor: Starling Bank Bikes\\n        We’re delighted to welcome Starling Bank on board as the new sponsors of our bike hire scheme.\\n                    \\n                        Learn more about new Starling Bank Bikes', metadata={'source': 'https://tfgm.com/travel-updates'})"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "texts[3]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsYsIy8F4cdm"
      },
      "source": [
        "## create the DB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_eTIZwf4Dk2",
        "outputId": "1cd293c4-716c-402d-d41b-045b6a264041"
      },
      "outputs": [],
      "source": [
        "# Embed and store the texts\n",
        "# Supplying a persist_directory will store the embeddings on disk\n",
        "persist_directory = 'db'\n",
        "\n",
        "## here we are using OpenAI embeddings but in future we will swap out to local embeddings\n",
        "embedding = OpenAIEmbeddings()\n",
        "\n",
        "vectordb = Chroma.from_documents(documents=texts,\n",
        "                                 embedding=embedding,\n",
        "                                 persist_directory=persist_directory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "uRfD_Te-47lb"
      },
      "outputs": [],
      "source": [
        "# persiste the db to disk\n",
        "vectordb.persist()\n",
        "vectordb = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-h1y_eAHmD-",
        "outputId": "4a6097fb-e30e-4fa2-ff4d-b972ce7f6154"
      },
      "outputs": [],
      "source": [
        "# Now we can load the persisted database from disk, and use it as normal.\n",
        "vectordb = Chroma(persist_directory=persist_directory,\n",
        "                  embedding_function=embedding)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "siLXR-XT0JoI"
      },
      "source": [
        "## Make a retriever"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "6ObunFU30Lxh"
      },
      "outputs": [],
      "source": [
        "retriever = vectordb.as_retriever()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "cYA-H59u0Skn"
      },
      "outputs": [],
      "source": [
        "docu = retriever.get_relevant_documents(\"How much money isfares?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0iAuh_B0ZjE",
        "outputId": "2ffd1da1-ff6c-4ea9-c361-7230dbd5bdc0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(docu)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "jVWgPJXs1yRq"
      },
      "outputs": [],
      "source": [
        "retriever = vectordb.as_retriever(search_kwargs={\"k\": 2})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "H4N0IhRM0hHL",
        "outputId": "f8058122-1c8a-4c5b-f046-14a90eed5a3b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'similarity'"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "retriever.search_type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jXL9u-u0prF",
        "outputId": "2e6dd94e-bede-4e05-c841-9c755ecfef2a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'k': 2}"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "retriever.search_kwargs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Ia-4OXa5IeP"
      },
      "source": [
        "## Make a chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "MGx8XblM4shW"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\python\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.llms.openai.OpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
            "  warn_deprecated(\n"
          ]
        }
      ],
      "source": [
        "# create the chain to answer questions\n",
        "qa_chain = RetrievalQA.from_chain_type(llm=OpenAI(),\n",
        "                                  chain_type=\"stuff\",\n",
        "                                  retriever=retriever,\n",
        "                                  return_source_documents=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "LZEo26mw8e5k"
      },
      "outputs": [],
      "source": [
        "## Cite sources\n",
        "def process_llm_response(llm_response):\n",
        "    print(llm_response['result'])\n",
        "    print('\\n\\nSources:')\n",
        "    for source in llm_response[\"source_documents\"]:\n",
        "        print(source.metadata['source'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKfX4vX-5RFT",
        "outputId": "b3902fd2-86cc-4020-86a9-99883a996d20"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\python\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " You can pay for tram travel using contactless payment methods, such as a debit or credit card with the contactless symbol, or a mobile wallet like Apple Pay or GPay. You simply need to touch in and out with your chosen payment method to start and end your journey, and you will be automatically charged the correct fare for your trip. \n",
            "\n",
            "\n",
            "Sources:\n",
            "https://tfgm.com/ways-to-pay/contactless-on-tram\n",
            "https://tfgm.com/ways-to-pay/contactless-on-tram\n"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "# full example\n",
        "query = \"How do I pay to use the tram?\"\n",
        "llm_response = qa_chain(query)\n",
        "process_llm_response(llm_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olRm73t3rNt2",
        "outputId": "20fb1b17-6562-421d-a60e-c67b97ca67d7"
      },
      "outputs": [],
      "source": [
        "# break it down\n",
        "query = \"How do I pay to use the tram?\"\n",
        "llm_response = qa_chain(query)\n",
        "# process_llm_response(llm_response)\n",
        "llm_response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wg-e6fh6rNwz",
        "outputId": "4b8d1e0e-b039-4e21-c233-a6c308cc5e25"
      },
      "outputs": [],
      "source": [
        "query = \"Who led the round in Pando?\"\n",
        "llm_response = qa_chain(query)\n",
        "process_llm_response(llm_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cuFf8D-rrN0I",
        "outputId": "19c63b88-33e2-4400-eede-f2678231eccb"
      },
      "outputs": [],
      "source": [
        "query = \"What did databricks acquire?\"\n",
        "llm_response = qa_chain(query)\n",
        "process_llm_response(llm_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5KETxphrN3d",
        "outputId": "4f4a7dfb-0f5b-4b72-b678-6def5d056d20"
      },
      "outputs": [],
      "source": [
        "query = \"What is generative ai?\"\n",
        "llm_response = qa_chain(query)\n",
        "process_llm_response(llm_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "692pHNkFrN5z",
        "outputId": "85124452-c208-4ec4-a35d-be28503ddc42"
      },
      "outputs": [],
      "source": [
        "query = \"Who is CMA?\"\n",
        "llm_response = qa_chain(query)\n",
        "process_llm_response(llm_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPIhZWAR5n3X",
        "outputId": "68914c62-f8ed-4e22-d889-7991df441d53"
      },
      "outputs": [],
      "source": [
        "qa_chain.retriever.search_type , qa_chain.retriever.vectorstore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_lp0_796P_-",
        "outputId": "64c01726-6e78-4c12-e409-2fdc839f6611"
      },
      "outputs": [],
      "source": [
        "print(qa_chain.combine_documents_chain.llm_chain.prompt.template)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSxVCnNi5h1-"
      },
      "source": [
        "## Deleteing the DB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7xmepGJ2GAE",
        "outputId": "92b53c84-ef81-4000-db5a-2c2ec09db311"
      },
      "outputs": [],
      "source": [
        "!zip -r db.zip ./db"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jl84qGQt5Wu5"
      },
      "outputs": [],
      "source": [
        "# To cleanup, you can delete the collection\n",
        "vectordb.delete_collection()\n",
        "vectordb.persist()\n",
        "\n",
        "# delete the directory\n",
        "!rm -rf db/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2r0ZIBPJp-K"
      },
      "source": [
        "## Starting again loading the db\n",
        "\n",
        "restart the runtime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8pc7CM_mTQAt",
        "outputId": "f8e311fb-7d68-43af-ffd6-f66a9259766a"
      },
      "outputs": [],
      "source": [
        "!unzip db.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "us3F8ZKeRiz2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qK1nY4PkKYGo"
      },
      "outputs": [],
      "source": [
        "from langchain.vectorstores import Chroma\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains import RetrievalQA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "396RyNbS4EXx",
        "outputId": "502d5c81-0823-4c00-89ca-7b4dd08bee26"
      },
      "outputs": [],
      "source": [
        "persist_directory = 'db'\n",
        "embedding = OpenAIEmbeddings()\n",
        "\n",
        "vectordb2 = Chroma(persist_directory=persist_directory,\n",
        "                  embedding_function=embedding,\n",
        "                   )\n",
        "\n",
        "retriever = vectordb2.as_retriever(search_kwargs={\"k\": 2})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F3vkSxxYKCZ9"
      },
      "outputs": [],
      "source": [
        "# Set up the turbo LLM\n",
        "turbo_llm = ChatOpenAI(\n",
        "    temperature=0,\n",
        "    model_name='gpt-3.5-turbo'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PsR60NH5KCfj"
      },
      "outputs": [],
      "source": [
        "# create the chain to answer questions\n",
        "qa_chain = RetrievalQA.from_chain_type(llm=turbo_llm,\n",
        "                                  chain_type=\"stuff\",\n",
        "                                  retriever=retriever,\n",
        "                                  return_source_documents=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RWulTG0eKCfk"
      },
      "outputs": [],
      "source": [
        "## Cite sources\n",
        "def process_llm_response(llm_response):\n",
        "    print(llm_response['result'])\n",
        "    print('\\n\\nSources:')\n",
        "    for source in llm_response[\"source_documents\"]:\n",
        "        print(source.metadata['source'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDp-g2FtKCfk",
        "outputId": "766f131a-daaf-462f-842a-f7bd10a081fd"
      },
      "outputs": [],
      "source": [
        "# full example\n",
        "query = \"How much money did Pando raise?\"\n",
        "llm_response = qa_chain(query)\n",
        "process_llm_response(llm_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fPl26c-TbWw"
      },
      "source": [
        "### Chat prompts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wwyuhrpu5XqM",
        "outputId": "0f2c8060-4002-49ba-8869-6a9990c2c6d6"
      },
      "outputs": [],
      "source": [
        "print(qa_chain.combine_documents_chain.llm_chain.prompt.messages[0].prompt.template)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LcWXvSCHRvHO",
        "outputId": "d7a3acee-9ef1-4c08-b2a0-187f2cd90c8f"
      },
      "outputs": [],
      "source": [
        "print(qa_chain.combine_documents_chain.llm_chain.prompt.messages[1].prompt.template)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "978QWCeJSRdu"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
